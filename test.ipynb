{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cryptpandas as crp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching recent messages...\n",
      "Extracted Data:\n",
      "  File Name: release_8411.crypt\n",
      "  Passcode: txpr5wCyFGPpKoqK\n",
      "Authenticating with Google Drive...\n",
      "Downloading file: release_8411.crypt\n",
      "Download 100% complete.\n",
      "File 'release_8411.crypt' downloaded successfully.\n",
      "Decrypting file: release_8411.crypt\n",
      "Decrypted DataFrame:\n",
      "       strat_0   strat_1   strat_2   strat_3    strat_4    strat_5   strat_6  \\\n",
      "0          NaN       NaN       NaN       NaN        NaN        NaN       NaN   \n",
      "1    -1.045104       NaN       NaN       NaN        NaN  10.139780  1.481773   \n",
      "2    -0.229267       NaN       NaN       NaN        NaN  10.109780  0.731916   \n",
      "3    -0.332475       NaN -0.056052       NaN        NaN   9.961956 -0.557418   \n",
      "4    -0.827446       NaN -0.349031       NaN        NaN   9.964834 -1.177777   \n",
      "...        ...       ...       ...       ...        ...        ...       ...   \n",
      "8407  0.419779 -0.521346  1.176597  1.955253   9.829158  10.269232 -0.463687   \n",
      "8408 -1.643896 -0.139856 -0.241196  0.537176  10.345547   9.700768 -0.523140   \n",
      "8409 -1.361392  0.626435 -0.965469 -2.604032   8.930698   9.587217  0.037979   \n",
      "8410 -0.059311  0.129570  0.621286 -0.549907   9.638139   9.963557 -1.228330   \n",
      "8411  0.315907 -0.494254  1.718611 -1.045009  10.183437  10.210182 -0.481943   \n",
      "\n",
      "       strat_7   strat_8   strat_9  ...  strat_88  strat_89  strat_90  \\\n",
      "0          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "1          NaN  1.298774       NaN  ... -0.582978       NaN       NaN   \n",
      "2          NaN  1.748748       NaN  ... -0.328429       NaN       NaN   \n",
      "3    -0.246940  0.043789       NaN  ... -0.042355       NaN       NaN   \n",
      "4    -0.795178 -1.105112       NaN  ... -0.066084       NaN       NaN   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "8407 -0.041913  0.441956 -0.439417  ...  0.442852  1.199994  0.612545   \n",
      "8408  0.503333  0.496595 -0.916920  ... -0.962170 -0.493424  1.353522   \n",
      "8409  0.882123  0.324213  0.377232  ... -1.115522 -2.527436 -0.367003   \n",
      "8410 -0.135813 -0.276736  1.279336  ... -0.117704 -0.262299 -0.405415   \n",
      "8411 -0.001222 -0.396570  0.861996  ...  0.549412  0.134633 -0.063001   \n",
      "\n",
      "      strat_91  strat_92  strat_93  strat_94  strat_95  strat_96  strat_97  \n",
      "0          NaN       NaN -1.285068       NaN       NaN       NaN       NaN  \n",
      "1          NaN       NaN  1.417147       NaN       NaN -1.742396       NaN  \n",
      "2          NaN       NaN  0.718038       NaN       NaN -0.931068       NaN  \n",
      "3          NaN -0.133318 -0.425376       NaN -1.853440  0.464871       NaN  \n",
      "4          NaN -1.354008 -0.856285       NaN -0.756152  0.115210       NaN  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "8407  0.408569  0.907095  0.014314  0.530580 -1.480708  0.108514 -0.496365  \n",
      "8408 -0.280246 -0.802394 -0.527215 -0.463975  0.591159 -0.999991 -0.931155  \n",
      "8409 -1.309089 -1.144910 -0.007809 -0.025203  2.456222 -0.914648  0.695651  \n",
      "8410  0.181546 -0.649986 -0.328697  0.535181 -0.028916  1.121448  1.194132  \n",
      "8411  0.711643  0.470819 -0.566747 -0.707417 -1.088007  0.326028  1.333297  \n",
      "\n",
      "[8412 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "from slack_sdk import WebClient\n",
    "import re\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2 import service_account\n",
    "import io\n",
    "import cryptpandas as crp\n",
    "\n",
    "slack_token = \"\"\n",
    "channel_id = \"C080P6M4DKL\"\n",
    "expected_user_email = \"------@gmail.com\"\n",
    "\n",
    "# Google Drive API credentials\n",
    "SERVICE_ACCOUNT_FILE = 'direct-volt-441912-r9-6b6d82e81e93.json'  # Replace with the path to your JSON key file\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "FOLDER_ID = '1ElVOO_4Plr24xEOmdqsINmIRM_y4M3_n'\n",
    "\n",
    "\n",
    "# Initialize the Slack client\n",
    "client = WebClient(token=slack_token)\n",
    "\n",
    "\n",
    "def fetch_recent_messages(channel_id, limit=30):\n",
    "    \"\"\"\n",
    "    Fetch recent messages from a Slack channel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.conversations_history(channel=channel_id, limit=limit)\n",
    "        messages = response.get('messages', [])\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching messages: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_user_email(user_id):\n",
    "    \"\"\"\n",
    "    Fetch the email of a user based on their Slack user ID.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.users_info(user=user_id)\n",
    "        email = response['user']['profile'].get('email', '')\n",
    "        return email\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching user info: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_data_file_and_passcode(messages):\n",
    "    \"\"\"\n",
    "    Extract the data file name and passcode from the messages.\n",
    "    \"\"\"\n",
    "    for message in messages:\n",
    "        text = message.get('text', '')\n",
    "        user_id = message.get('user', '')\n",
    "        # Verify the user's email\n",
    "        user_email = get_user_email(user_id)\n",
    "        if user_email == expected_user_email:\n",
    "            match = re.search(\n",
    "                r\"Data has just been released '(.+?)' the passcode is '(.+?)'\\.\",\n",
    "                text\n",
    "            )\n",
    "            if match:\n",
    "                file_name = match.group(1)\n",
    "                passcode = match.group(2)\n",
    "                return file_name, passcode\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def authenticate_google_drive():\n",
    "    \"\"\"\n",
    "    Authenticate and initialize the Google Drive API client.\n",
    "    \"\"\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "    return service\n",
    "\n",
    "\n",
    "def find_and_download_file(service, file_name):\n",
    "    \"\"\"\n",
    "    Find a file by name in the specified folder and download it.\n",
    "    \"\"\"\n",
    "    query = f\"'{FOLDER_ID}' in parents and name='{file_name}'\"\n",
    "    results = service.files().list(q=query, spaces='drive').execute()\n",
    "    files = results.get('files', [])\n",
    "\n",
    "    if not files:\n",
    "        print(f\"File '{file_name}' not found in the folder.\")\n",
    "        return False\n",
    "\n",
    "    file_id = files[0]['id']\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    fh = io.FileIO(file_name, 'wb')\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(f\"Download {int(status.progress() * 100)}% complete.\")\n",
    "    \n",
    "    print(f\"File '{file_name}' downloaded successfully.\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def decrypt_file(file_name, passcode):\n",
    "    \"\"\"\n",
    "    Decrypt the downloaded file using the provided passcode.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        decrypted_df = crp.read_encrypted(path=file_name, password=passcode)\n",
    "        decrypted_df.to_csv('latest_data.csv', index=False)\n",
    "        print(\"Decrypted DataFrame:\")\n",
    "        print(decrypted_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error decrypting file: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Fetch recent messages from the Slack channel\n",
    "    print(\"Fetching recent messages...\")\n",
    "    messages = fetch_recent_messages(channel_id)\n",
    "\n",
    "    if not messages:\n",
    "        print(\"No messages found or error in fetching messages.\")\n",
    "        exit()\n",
    "\n",
    "    # Step 2: Extract file name and passcode\n",
    "    file_name, passcode = extract_data_file_and_passcode(messages)\n",
    "\n",
    "    if not (file_name and passcode):\n",
    "        print(\"No matching message found or sender did not match.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Extracted Data:\")\n",
    "    print(f\"  File Name: {file_name}\")\n",
    "    print(f\"  Passcode: {passcode}\")\n",
    "\n",
    "    # Step 3: Authenticate Google Drive\n",
    "    print(\"Authenticating with Google Drive...\")\n",
    "    service = authenticate_google_drive()\n",
    "\n",
    "    # Step 4: Download the file from Google Drive\n",
    "    print(f\"Downloading file: {file_name}\")\n",
    "    if not find_and_download_file(service, file_name):\n",
    "        print(\"File download failed.\")\n",
    "        exit()\n",
    "\n",
    "    # Step 5: Decrypt the file\n",
    "    print(f\"Decrypting file: {file_name}\")\n",
    "    decrypt_file(file_name, passcode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted_df = crp.read_encrypted(path=file_name, password=passcode)\n",
    "\n",
    "#   File Name: release_8027.crypt\n",
    "#   Passcode: xwDXIhUaJe9V4bVR\n",
    "#   File Name: release_5467.crypt\n",
    "\n",
    "#   File Name: release_5595.crypt\n",
    "#   Passcode: bsCATJi4sHpcSZFZ\n",
    "# #\n",
    "#   Passcode: CfEJCI8NjykYKV73\n",
    "# done :release_3547: oUFtGMsMEEyPCCP6, release_3611 : GMJVDf4WWzsV1hfL, release_3675: PSI9bPh4aM3iQMuE\n",
    "# release_3739: 1vA9LaAZDTEKPePs,release_3803 : 0n74wuaJ2wm8A4qC, release_3867 : mXTi0PZ5oL731Zqx\n",
    "# release_3931: hjhMuDFZTCJEcI6q\n",
    "# release_3995 : uZwgENGlQ4m4nSz6\n",
    "# release_4059 : HkpYXpKituGernrk\n",
    "# release_4123 : WM5xrwsJiBCo4Unp\n",
    "# release_4187 : InhVD4qy1Vmbpl5c\n",
    "\n",
    "# release_4251 : VRiYLce0BKVSdrft\n",
    "# release_4315 : UR7git7mIlV7HdyY\n",
    "# release_4379 : scZ5oIa3vp1uzE4S\n",
    "\n",
    "# release_4571 ! WPcFk8FofuBmfUzO\n",
    "# release_4635 : hpuTAsG3v5av6J0D\n",
    "# release_4699 : iqKVo38SFhsSz9qX\n",
    "\n",
    "# release_4891 : 9YAePHMaPzZKmsmv\n",
    "\n",
    "#   File Name: release_4955.crypt\n",
    "#   Passcode: sL7KZHNduMf2Cy5D\n",
    "\n",
    "#   File Name: release_5275.crypt\n",
    "#   Passcode: ljo2F8g5X6TWJXmX\n",
    "\n",
    "#  File Name: release_5403.crypt\n",
    "#   Passcode: F8CvtiKofpaT7IeO\n",
    "# File Name: release_5531.crypt\n",
    "#   Passcode: 9xzhWOAuImRy1cQB\n",
    "# df_filled = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de valeurs NaN après remplacement des infinis : 3\n",
      "Nombre total de valeurs NaN après traitement : 0\n"
     ]
    }
   ],
   "source": [
    "df_filled = decrypted_df.ffill().bfill().fillna(decrypted_df.mean())\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Remplacer les valeurs infinies par NaN\n",
    "df_filled.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Vérifier combien de valeurs NaN sont présentes\n",
    "print(\"Nombre total de valeurs NaN après remplacement des infinis :\", df_filled.isna().sum().sum())\n",
    "\n",
    "# Option 1 : Supprimer les lignes contenant des NaN\n",
    "# returns.dropna(inplace=True)\n",
    "\n",
    "# Option 2 : Remplacer les NaN par une autre valeur, comme la moyenne de chaque colonne\n",
    "df_filled.fillna(df_filled.mean(), inplace=True)\n",
    "\n",
    "# Vérifier s'il reste des NaN après le traitement\n",
    "print(\"Nombre total de valeurs NaN après traitement :\", df_filled.isna().sum().sum())\n",
    "\n",
    "returns = df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de valeurs NaN après remplacement des infinis : 0\n",
      "Nombre total de valeurs NaN après traitement : 0\n",
      "Returns DataFrame shape after preprocessing: (8412, 98)\n",
      "Returns DataFrame after scaling:\n",
      "    strat_0   strat_1   strat_2   strat_3  strat_4   strat_5   strat_6  \\\n",
      "0 -0.937183  0.045734 -0.053409  0.147609 -0.96883  0.116622  1.433698   \n",
      "1 -0.937183  0.045734 -0.053409  0.147609 -0.96883  0.116622  1.433698   \n",
      "2 -0.210877  0.045734 -0.053409  0.147609 -0.96883  0.088900  0.717783   \n",
      "3 -0.302759  0.045734 -0.053409  0.147609 -0.96883 -0.047701 -0.513192   \n",
      "4 -0.743411  0.045734 -0.330009  0.147609 -0.96883 -0.045042 -1.105471   \n",
      "\n",
      "    strat_7   strat_8   strat_9  ...  strat_88  strat_89  strat_90  strat_91  \\\n",
      "0 -0.271115  1.116291 -0.010904  ... -0.550829  0.653601 -1.065846 -0.699212   \n",
      "1 -0.271115  1.116291 -0.010904  ... -0.550829  0.653601 -1.065846 -0.699212   \n",
      "2 -0.271115  1.510500 -0.010904  ... -0.315475  0.653601 -1.065846 -0.699212   \n",
      "3 -0.271115  0.016834 -0.010904  ... -0.050974  0.653601 -1.065846 -0.699212   \n",
      "4 -0.785263 -0.989685 -0.010904  ... -0.072913  0.653601 -1.065846 -0.699212   \n",
      "\n",
      "   strat_92  strat_93  strat_94  strat_95  strat_96  strat_97  \n",
      "0 -0.123619 -1.184106 -1.673756 -1.844026 -1.422289  0.683522  \n",
      "1 -0.123619  1.283036 -1.673756 -1.844026 -1.422289  0.683522  \n",
      "2 -0.123619  0.644744 -1.673756 -1.844026 -0.752309  0.683522  \n",
      "3 -0.123619 -0.399201 -1.673756 -1.844026  0.400433  0.683522  \n",
      "4 -1.339768 -0.792624 -1.673756 -0.784738  0.111689  0.683522  \n",
      "\n",
      "[5 rows x 98 columns]\n",
      "Training model for strat_0...\n",
      "Training model for strat_1...\n",
      "Training model for strat_2...\n",
      "Training model for strat_3...\n",
      "Training model for strat_4...\n",
      "Training model for strat_5...\n",
      "Training model for strat_6...\n",
      "Training model for strat_7...\n",
      "Training model for strat_8...\n",
      "Training model for strat_9...\n",
      "Training model for strat_10...\n",
      "Training model for strat_11...\n",
      "Training model for strat_12...\n",
      "Training model for strat_13...\n",
      "Training model for strat_14...\n",
      "Training model for strat_15...\n",
      "Training model for strat_16...\n",
      "Training model for strat_17...\n",
      "Training model for strat_18...\n",
      "Training model for strat_19...\n",
      "Training model for strat_20...\n",
      "Training model for strat_21...\n",
      "Training model for strat_22...\n",
      "Training model for strat_23...\n",
      "Training model for strat_24...\n",
      "Training model for strat_25...\n",
      "Training model for strat_26...\n",
      "Training model for strat_27...\n",
      "Training model for strat_28...\n",
      "Training model for strat_29...\n",
      "Training model for strat_30...\n",
      "Training model for strat_31...\n",
      "Training model for strat_32...\n",
      "Training model for strat_33...\n",
      "Training model for strat_34...\n",
      "Training model for strat_35...\n",
      "Training model for strat_36...\n",
      "Training model for strat_37...\n",
      "Training model for strat_38...\n",
      "Training model for strat_39...\n",
      "Training model for strat_40...\n",
      "Training model for strat_41...\n",
      "Training model for strat_42...\n",
      "Training model for strat_43...\n",
      "Training model for strat_44...\n",
      "Training model for strat_45...\n",
      "Training model for strat_46...\n",
      "Training model for strat_47...\n",
      "Training model for strat_48...\n",
      "Training model for strat_49...\n",
      "Training model for strat_50...\n",
      "Training model for strat_51...\n",
      "Training model for strat_52...\n",
      "Training model for strat_53...\n",
      "Training model for strat_54...\n",
      "Training model for strat_55...\n",
      "Training model for strat_56...\n",
      "Training model for strat_57...\n",
      "Training model for strat_58...\n",
      "Training model for strat_59...\n",
      "Training model for strat_60...\n",
      "Training model for strat_61...\n",
      "Training model for strat_62...\n",
      "Training model for strat_63...\n",
      "Training model for strat_64...\n",
      "Training model for strat_65...\n",
      "Training model for strat_66...\n",
      "Training model for strat_67...\n",
      "Training model for strat_68...\n",
      "Training model for strat_69...\n",
      "Training model for strat_70...\n",
      "Training model for strat_71...\n",
      "Training model for strat_72...\n",
      "Training model for strat_73...\n",
      "Training model for strat_74...\n",
      "Training model for strat_75...\n",
      "Training model for strat_76...\n",
      "Training model for strat_77...\n",
      "Training model for strat_78...\n",
      "Training model for strat_79...\n",
      "Training model for strat_80...\n",
      "Training model for strat_81...\n",
      "Training model for strat_82...\n",
      "Training model for strat_83...\n",
      "Training model for strat_84...\n",
      "Training model for strat_85...\n",
      "Training model for strat_86...\n",
      "Training model for strat_87...\n",
      "Training model for strat_88...\n",
      "Training model for strat_89...\n",
      "Training model for strat_90...\n",
      "Training model for strat_91...\n",
      "Training model for strat_92...\n",
      "Training model for strat_93...\n",
      "Training model for strat_94...\n",
      "Training model for strat_95...\n",
      "Training model for strat_96...\n",
      "Training model for strat_97...\n",
      "\n",
      "Expected Returns per Asset:\n",
      "strat_0      0.006947\n",
      "strat_1     -0.111465\n",
      "strat_2     -0.012121\n",
      "strat_3      0.068711\n",
      "strat_4     10.070592\n",
      "              ...    \n",
      "strat_93     0.022607\n",
      "strat_94     0.018531\n",
      "strat_95     0.058926\n",
      "strat_96    -0.024297\n",
      "strat_97     0.057315\n",
      "Length: 98, dtype: float64\n",
      "\n",
      "Optimal portfolio allocation:\n",
      "  strat_1: 0.0039798794693241\n",
      "  strat_2: 0.0000000000921455\n",
      "  strat_4: 0.1000000000000000\n",
      "  strat_5: 0.1000000000000000\n",
      "  strat_7: 0.0000000000294132\n",
      "  strat_8: 0.0000000000314730\n",
      "  strat_9: 0.0040478156737121\n",
      "  strat_10: 0.0532428025292495\n",
      "  strat_12: 0.0067723579673115\n",
      "  strat_13: 0.0552431737856839\n",
      "  strat_14: 0.0062323697229335\n",
      "  strat_18: 0.0332422180413752\n",
      "  strat_19: 0.0000000000021861\n",
      "  strat_20: 0.1000000000000000\n",
      "  strat_22: 0.0456574657171577\n",
      "  strat_29: 0.0000000001399460\n",
      "  strat_30: 0.0000000000299152\n",
      "  strat_32: 0.0000000000438759\n",
      "  strat_33: 0.0265501378703515\n",
      "  strat_34: 0.0000000000332243\n",
      "  strat_36: 0.0000000001021758\n",
      "  strat_38: 0.0000000000608250\n",
      "  strat_39: 0.0027349859098618\n",
      "  strat_44: 0.0892738767032446\n",
      "  strat_45: 0.0527525603874913\n",
      "  strat_50: 0.0000000000212738\n",
      "  strat_51: 0.0000000000599620\n",
      "  strat_52: 0.0334789277354887\n",
      "  strat_55: 0.0180895232168485\n",
      "  strat_57: 0.0000000000101302\n",
      "  strat_59: 0.0000000002791250\n",
      "  strat_62: 0.0071032508926309\n",
      "  strat_63: 0.0000000000254646\n",
      "  strat_65: 0.0055057242755720\n",
      "  strat_71: 0.0000000000611264\n",
      "  strat_75: 0.0000000000328781\n",
      "  strat_76: 0.0446485748535456\n",
      "  strat_77: 0.0091594820977827\n",
      "  strat_79: 0.0000000002765254\n",
      "  strat_80: 0.0530624285537077\n",
      "  strat_81: 0.0000000000024219\n",
      "  strat_82: 0.0000000000194787\n",
      "  strat_84: 0.0472568358794836\n",
      "  strat_85: 0.0098764595498028\n",
      "  strat_92: 0.0092046626080542\n",
      "  strat_95: 0.0828844892395632\n",
      "  strat_97: 0.0000000000443109\n",
      "Expected portfolio return: 199.94%\n",
      "Portfolio volatility: 13.86%\n",
      "Sharpe Ratio: 14.36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assume 'returns' is your DataFrame with historical returns of 49 strategies\n",
    "# For example: returns = pd.read_csv('your_returns_data.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Since the actual data is not provided, the following code assumes 'returns' is already loaded\n",
    "# If 'df_filled' is your DataFrame, ensure it is properly loaded\n",
    "# For the purpose of this code, we'll proceed as if 'returns' is your data\n",
    "\n",
    "# Data Preprocessing\n",
    "# Replace infinite values with NaN and drop columns with NaNs\n",
    "returns = returns.replace([np.inf, -np.inf], np.nan)\n",
    "print(\"Nombre total de valeurs NaN après remplacement des infinis :\", returns.isna().sum().sum())\n",
    "returns = returns.dropna(axis=1)\n",
    "print(\"Nombre total de valeurs NaN après traitement :\", returns.isna().sum().sum())\n",
    "print(\"Returns DataFrame shape after preprocessing:\", returns.shape)\n",
    "\n",
    "# Scale the returns data\n",
    "scaler = StandardScaler()\n",
    "returns_scaled = pd.DataFrame(scaler.fit_transform(returns), columns=returns.columns, index=returns.index)\n",
    "print(\"Returns DataFrame after scaling:\")\n",
    "print(returns_scaled.head())\n",
    "\n",
    "# Function to create lagged features\n",
    "def create_lagged_features(data, lag=1):\n",
    "    df = data.copy()\n",
    "    column_name = df.columns[0]\n",
    "    for i in range(1, lag+1):\n",
    "        df[f'Lag_{i}'] = df[column_name].shift(i)\n",
    "    return df.dropna()\n",
    "\n",
    "lag = 5  # Number of lagged days to use as features\n",
    "predicted_returns = pd.DataFrame(index=returns_scaled.index, columns=returns_scaled.columns)\n",
    "\n",
    "for asset in returns_scaled.columns:\n",
    "    print(f\"Training model for {asset}...\")\n",
    "    data = returns_scaled[[asset]]\n",
    "    data_lagged = create_lagged_features(data, lag)\n",
    "    X = data_lagged.drop(asset, axis=1)\n",
    "    y = data_lagged[asset]\n",
    "\n",
    "    # Time series split\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    predictions = pd.Series(index=y.index)\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "\n",
    "        # XGBoost regressor\n",
    "        model = XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        predictions.iloc[test_index] = y_pred\n",
    "\n",
    "    predicted_returns[asset] = predictions\n",
    "\n",
    "# Drop any rows with NaN predictions\n",
    "predicted_returns = predicted_returns.dropna()\n",
    "\n",
    "# **Data Cleaning: Clipping Extreme Values in Predicted Returns**\n",
    "# Clip predicted returns to a reasonable range (e.g., between -3 and 3 standard deviations)\n",
    "predicted_returns = predicted_returns.clip(lower=-3, upper=3)\n",
    "\n",
    "# Re-scale predicted returns back to original scale\n",
    "predicted_returns_unscaled = pd.DataFrame(\n",
    "    scaler.inverse_transform(predicted_returns),\n",
    "    columns=predicted_returns.columns,\n",
    "    index=predicted_returns.index\n",
    ")\n",
    "\n",
    "# Calculate expected returns from the predictions\n",
    "expected_returns = predicted_returns_unscaled.mean()\n",
    "print(\"\\nExpected Returns per Asset:\")\n",
    "print(expected_returns)\n",
    "\n",
    "# Calculate the covariance matrix from historical data (scaled returns)\n",
    "cov_matrix = returns_scaled.loc[predicted_returns.index].cov()\n",
    "\n",
    "# **Optimization**\n",
    "\n",
    "def portfolio_performance(weights, expected_returns, cov_matrix):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return portfolio_return, portfolio_volatility\n",
    "\n",
    "def neg_sharpe_ratio(weights, expected_returns, cov_matrix, risk_free_rate=0.01):\n",
    "    p_return, p_volatility = portfolio_performance(weights, expected_returns, cov_matrix)\n",
    "    sharpe_ratio = (p_return - risk_free_rate) / p_volatility\n",
    "    return -sharpe_ratio  # Negative because we minimize\n",
    "\n",
    "# Constraints: Sum of weights = 1, weights between 0% and 10%\n",
    "constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]\n",
    "bounds = tuple((0, 0.1) for _ in range(len(expected_returns)))\n",
    "\n",
    "# Initial guess\n",
    "num_assets = len(expected_returns)\n",
    "initial_weights = num_assets * [1. / num_assets,]\n",
    "\n",
    "# Optimization\n",
    "options = {'disp': False}\n",
    "result = minimize(neg_sharpe_ratio, initial_weights, args=(expected_returns, cov_matrix),\n",
    "                  method='SLSQP', bounds=bounds, constraints=constraints, options=options)\n",
    "\n",
    "optimal_weights = result.x\n",
    "p_return, p_volatility = portfolio_performance(optimal_weights, expected_returns, cov_matrix)\n",
    "sharpe_ratio = (p_return - 0.01) / p_volatility\n",
    "\n",
    "# Display results\n",
    "print(\"\\nOptimal portfolio allocation:\")\n",
    "for i, weight in enumerate(optimal_weights):\n",
    "    if weight > 0:\n",
    "        print(f\"  {returns.columns[i]}: {weight:.16f}\")\n",
    "print(f\"Expected portfolio return: {p_return:.2%}\")\n",
    "print(f\"Portfolio volatility: {p_volatility:.2%}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'strat_0': '0.00000000000000000000', 'strat_1': '0.00397987945309396119', 'strat_2': '0.00000000009214547768', 'strat_3': '0.00000000000000000000', 'strat_4': '0.09999999959219466050', 'strat_5': '0.09999999959219466050', 'strat_6': '0.00000000000000000000', 'strat_7': '0.00000000002941315324', 'strat_8': '0.00000000003147299615', 'strat_9': '0.00404781565720488314', 'strat_10': '0.05324280231212252107', 'strat_11': '0.00000000000000000000', 'strat_12': '0.00677235793969342779', 'strat_13': '0.05524317356039924742', 'strat_14': '0.00623236969751760853', 'strat_15': '0.00000000000000000000', 'strat_16': '0.00000000000000000000', 'strat_17': '0.00000000000000000000', 'strat_18': '0.03324221790581163849', 'strat_19': '0.00000000000218608775', 'strat_20': '0.09999999959219466050', 'strat_21': '0.00000000000000000000', 'strat_22': '0.04565746553096412808', 'strat_23': '0.00000000000000000000', 'strat_24': '0.00000000000000000000', 'strat_25': '0.00000000000000000000', 'strat_26': '0.00000000000000000000', 'strat_27': '0.00000000000000000000', 'strat_28': '0.00000000000000000000', 'strat_29': '0.00000000013994600090', 'strat_30': '0.00000000002991515665', 'strat_31': '0.00000000000000000000', 'strat_32': '0.00000000004387594369', 'strat_33': '0.02655013776207859263', 'strat_34': '0.00000000003322428258', 'strat_35': '0.00000000000000000000', 'strat_36': '0.00000000010217575754', 'strat_37': '0.00000000000000000000', 'strat_38': '0.00000000006082500842', 'strat_39': '0.00273498589870841856', 'strat_40': '0.00000000000000000000', 'strat_41': '0.00000000000000000000', 'strat_42': '0.00000000000000000000', 'strat_43': '0.00000000000000000000', 'strat_44': '0.08927387633918100474', 'strat_45': '0.05275256017236348849', 'strat_46': '0.00000000000000000000', 'strat_47': '0.00000000000000000000', 'strat_48': '0.00000000000000000000', 'strat_49': '0.00000000000000000000', 'strat_50': '0.00000000002127377285', 'strat_51': '0.00000000005996195768', 'strat_52': '0.03347892759895979703', 'strat_53': '0.00000000000000000000', 'strat_54': '0.00000000000000000000', 'strat_55': '0.01808952314307846893', 'strat_56': '0.00000000000000000000', 'strat_57': '0.00000000001013020559', 'strat_58': '0.00000000000000000000', 'strat_59': '0.00000000027912498954', 'strat_60': '0.00000000000000000000', 'strat_61': '0.00000000000000000000', 'strat_62': '0.00710325086366345518', 'strat_63': '0.00000000002546458246', 'strat_64': '0.00000000000000000000', 'strat_65': '0.00550572425311940047', 'strat_66': '0.00000000000000000000', 'strat_67': '0.00000000000000000000', 'strat_68': '0.00000000000000000000', 'strat_69': '0.00000000000000000000', 'strat_70': '0.00000000000000000000', 'strat_71': '0.00000000006112640230', 'strat_72': '0.00000000000000000000', 'strat_73': '0.00000000000000000000', 'strat_74': '0.00000000000000000000', 'strat_75': '0.00000000003287809560', 'strat_76': '0.04464857467146634423', 'strat_77': '0.00915948206042987122', 'strat_78': '0.00000000000000000000', 'strat_79': '0.00000000027652544009', 'strat_80': '0.05306242833731626696', 'strat_81': '0.00000000000242190895', 'strat_82': '0.00000000001947867301', 'strat_83': '0.00000000000000000000', 'strat_84': '0.04725683568676772306', 'strat_85': '0.00987645950952611117', 'strat_86': '0.00000000000000000000', 'strat_87': '0.00000000000000000000', 'strat_88': '0.00000000000000000000', 'strat_89': '0.00000000000000000000', 'strat_90': '0.00000000000000000000', 'strat_91': '0.00000000000000000000', 'strat_92': '0.00920466257051713241', 'strat_93': '0.00000000000000000000', 'strat_94': '0.00000000000000000000', 'strat_95': '0.08288448890155586390', 'strat_96': '0.00000000000000000000', 'strat_97': '0.00000000004431088089', 'team_name': 'moonwalkers', 'passcode': 'osihamedmarkmoonwalkers'}\n",
      "{'strat_0': '0.00000000000000000000', 'strat_1': '0.00397987945309396119', 'strat_2': '0.00000000009214547768', 'strat_3': '0.00000000000000000000', 'strat_4': '0.09999999959219466050', 'strat_5': '0.09999999959219466050', 'strat_6': '0.00000000000000000000', 'strat_7': '0.00000000002941315324', 'strat_8': '0.00000000003147299615', 'strat_9': '0.00404781565720488314', 'strat_10': '0.05324280231212252107', 'strat_11': '0.00000000000000000000', 'strat_12': '0.00677235793969342779', 'strat_13': '0.05524317356039924742', 'strat_14': '0.00623236969751760853', 'strat_15': '0.00000000000000000000', 'strat_16': '0.00000000000000000000', 'strat_17': '0.00000000000000000000', 'strat_18': '0.03324221790581163849', 'strat_19': '0.00000000000218608775', 'strat_20': '0.09999999959219466050', 'strat_21': '0.00000000000000000000', 'strat_22': '0.04565746553096412808', 'strat_23': '0.00000000000000000000', 'strat_24': '0.00000000000000000000', 'strat_25': '0.00000000000000000000', 'strat_26': '0.00000000000000000000', 'strat_27': '0.00000000000000000000', 'strat_28': '0.00000000000000000000', 'strat_29': '0.00000000013994600090', 'strat_30': '0.00000000002991515665', 'strat_31': '0.00000000000000000000', 'strat_32': '0.00000000004387594369', 'strat_33': '0.02655013776207859263', 'strat_34': '0.00000000003322428258', 'strat_35': '0.00000000000000000000', 'strat_36': '0.00000000010217575754', 'strat_37': '0.00000000000000000000', 'strat_38': '0.00000000006082500842', 'strat_39': '0.00273498589870841856', 'strat_40': '0.00000000000000000000', 'strat_41': '0.00000000000000000000', 'strat_42': '0.00000000000000000000', 'strat_43': '0.00000000000000000000', 'strat_44': '0.08927387633918100474', 'strat_45': '0.05275256017236348849', 'strat_46': '0.00000000000000000000', 'strat_47': '0.00000000000000000000', 'strat_48': '0.00000000000000000000', 'strat_49': '0.00000000000000000000', 'strat_50': '0.00000000002127377285', 'strat_51': '0.00000000005996195768', 'strat_52': '0.03347892759895979703', 'strat_53': '0.00000000000000000000', 'strat_54': '0.00000000000000000000', 'strat_55': '0.01808952314307846893', 'strat_56': '0.00000000000000000000', 'strat_57': '0.00000000001013020559', 'strat_58': '0.00000000000000000000', 'strat_59': '0.00000000027912498954', 'strat_60': '0.00000000000000000000', 'strat_61': '0.00000000000000000000', 'strat_62': '0.00710325086366345518', 'strat_63': '0.00000000002546458246', 'strat_64': '0.00000000000000000000', 'strat_65': '0.00550572425311940047', 'strat_66': '0.00000000000000000000', 'strat_67': '0.00000000000000000000', 'strat_68': '0.00000000000000000000', 'strat_69': '0.00000000000000000000', 'strat_70': '0.00000000000000000000', 'strat_71': '0.00000000006112640230', 'strat_72': '0.00000000000000000000', 'strat_73': '0.00000000000000000000', 'strat_74': '0.00000000000000000000', 'strat_75': '0.00000000003287809560', 'strat_76': '0.04464857467146634423', 'strat_77': '0.00915948206042987122', 'strat_78': '0.00000000000000000000', 'strat_79': '0.00000000027652544009', 'strat_80': '0.05306242833731626696', 'strat_81': '0.00000000000242190895', 'strat_82': '0.00000000001947867301', 'strat_83': '0.00000000000000000000', 'strat_84': '0.04725683568676772306', 'strat_85': '0.00987645950952611117', 'strat_86': '0.00000000000000000000', 'strat_87': '0.00000000000000000000', 'strat_88': '0.00000000000000000000', 'strat_89': '0.00000000000000000000', 'strat_90': '0.00000000000000000000', 'strat_91': '0.00000000000000000000', 'strat_92': '0.00920466257051713241', 'strat_93': '0.00000000000000000000', 'strat_94': '0.00000000000000000000', 'strat_95': '0.08288448890155586390', 'strat_96': '0.00000000000000000000', 'strat_97': '0.00000000004431088089', 'team_name': 'moonwalkers', 'passcode': 'osihamedmarkmoonwalkers'}\n"
     ]
    }
   ],
   "source": [
    "def create_submission_dict(optimal_weights):\n",
    "    # Map weights to asset names\n",
    "    pos_dict = {}\n",
    "    for i, weight in enumerate(optimal_weights):\n",
    "        asset_name = returns.columns[i]\n",
    "        pos_dict[asset_name] = weight\n",
    "\n",
    "    # Submission checker functions\n",
    "    def get_positions(pos_dict):\n",
    "        pos = pd.Series(pos_dict)\n",
    "        pos = pos.replace([np.inf, -np.inf], np.nan)\n",
    "        pos = pos.dropna()\n",
    "        pos = pos / pos.abs().sum()\n",
    "        pos = pos.clip(-0.1, 0.1)\n",
    "        if pos.abs().max() / pos.abs().sum() > 0.1:\n",
    "            raise ValueError(f\"Portfolio too concentrated {pos.abs().max()=} / {pos.abs().sum()=}\")\n",
    "        return pos\n",
    "\n",
    "    def get_submission_dict(\n",
    "        pos_dict,\n",
    "        your_team_name: str = \"moonwalkers\",\n",
    "        your_team_passcode: str = \"osihamedmarkmoonwalkers\",\n",
    "    ):\n",
    "        positions = get_positions(pos_dict)\n",
    "        # Format the weights to 20 decimal places as strings\n",
    "        positions = positions.apply(lambda x: f\"{x:.20f}\")\n",
    "        return {\n",
    "            **positions.to_dict(),\n",
    "            **{\n",
    "                \"team_name\": your_team_name,\n",
    "                \"passcode\": your_team_passcode,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    # Create the submission dictionary\n",
    "    submission_dict = get_submission_dict(\n",
    "        pos_dict,\n",
    "        your_team_name=\"moonwalkers\",\n",
    "        your_team_passcode=\"osihamedmarkmoonwalkers\",\n",
    "    )\n",
    "\n",
    "    return submission_dict\n",
    "\n",
    "submission_answer = create_submission_dict(optimal_weights)\n",
    "print(submission_answer)\n",
    "\n",
    "submission_string = str(submission_answer)\n",
    "print(submission_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "\n",
    "# # Define the form URL\n",
    "# form_url = 'https://docs.google.com/forms/d/e/1FAIpQLSeUYMkI5ce18RL2aF5C8I7mPxF7haH23VEVz7PQrvz0Do0NrQ/viewform'\n",
    "\n",
    "\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(r\"--user-data-dir=C:\\Users\\theha\\AppData\\Local\\Google\\Chrome\\User Data\") #e.g. C:\\Users\\You\\AppData\\Local\\Google\\Chrome\\User Data\n",
    "# options.add_argument(r'--profile-directory=Profile 1') #e.g. Profile 3\n",
    "\n",
    "\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# try:\n",
    "#     # Step 1: Navigate to the Google Form\n",
    "#     driver.get(form_url)\n",
    "#     time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "#     # Step 2: Press the checkbox button\n",
    "#     checkbox = driver.find_element(By.XPATH, '//div[@id=\"i5\"]')\n",
    "#     checkbox.click()\n",
    "#     time.sleep(1)  # Allow time for the checkbox to register\n",
    "\n",
    "#     # Step 3: Fill out the textarea field with your answer\n",
    "#     # textarea = driver.find_element(By.XPATH, '//textarea[@class=\"KHxj8b tL9Q4c\"][@aria-label=\"Your answer\"]')\n",
    "\n",
    "#     textarea_container = driver.find_element(By.XPATH, '//div[@class=\"edhGSc zKHdkd kRy7qc RdH0ib yqQS1\"]')\n",
    "#     textarea = textarea_container.find_element(By.XPATH, './/textarea[@aria-label=\"Your answer\"]')\n",
    "#     textarea.send_keys(submission_string)  # Replace with your answer\n",
    "#     time.sleep(2)  # Allow time for input\n",
    "\n",
    "#     # Step 4: Press the Submit button\n",
    "#     submit_button = driver.find_element(By.XPATH, '//span[@class=\"NPEfkd RveJvd snByac\"][text()=\"Submit\"]')\n",
    "#     submit_button.click()\n",
    "#     time.sleep(3)  # Wait for the submission to process\n",
    "\n",
    "#     print(\"Form submitted successfully.\", submission_string)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "\n",
    "# finally:\n",
    "#     driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy.optimize import minimize\n",
    "\n",
    "# # Supposons que 'returns' soit un DataFrame avec les rendements des stratégies\n",
    "# # Exemple : returns = pd.DataFrame({...})\n",
    "\n",
    "# # Suppression des NaNs et des valeurs infinies\n",
    "# returns = returns.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "# print(\"Returns DataFrame shape after preprocessing:\", returns.shape)\n",
    "\n",
    "# # Check if returns DataFrame is empty\n",
    "# if returns.empty:\n",
    "#     raise ValueError(\"The 'returns' DataFrame is empty after preprocessing. Please check your data.\")\n",
    "\n",
    "# # **Standardize the data for PCA**\n",
    "# scaler = StandardScaler()\n",
    "# returns_scaled = pd.DataFrame(scaler.fit_transform(returns), columns=returns.columns)\n",
    "# print(\"Returns DataFrame after scaling:\")\n",
    "# print(returns_scaled.head())\n",
    "\n",
    "# # **Calculate mean returns and covariance matrix from original data**\n",
    "# mean_returns = returns.mean()\n",
    "# cov_matrix = returns.cov()\n",
    "\n",
    "# # **Perform PCA on the scaled data**\n",
    "# pca = PCA()\n",
    "# pca.fit(returns_scaled)\n",
    "\n",
    "# # Verify PCA components\n",
    "# print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "# print(\"Total Explained Variance:\", np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# # Keep components that explain 80% of the variance\n",
    "# cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "# n_components = np.argmax(cumulative_variance >= 0.8) + 1\n",
    "# print(f\"Number of components to reach 80% variance: {n_components}\")\n",
    "\n",
    "# # Obtain the top principal components\n",
    "# top_components = pca.components_[:n_components]\n",
    "# print(\"Top Components Shape:\", top_components.shape)\n",
    "\n",
    "# # Calculate the contribution of each strategy to the principal components\n",
    "# strategy_contributions = np.sum(np.abs(top_components), axis=0)\n",
    "# print(\"Strategy Contributions:\", strategy_contributions)\n",
    "\n",
    "# # Create a DataFrame to list strategies and their contributions\n",
    "# strategy_contributions_df = pd.DataFrame({\n",
    "#     'Strategy': returns.columns,\n",
    "#     'Contribution': strategy_contributions\n",
    "# })\n",
    "\n",
    "# # Verify if total_contribution is zero\n",
    "# total_contribution = strategy_contributions_df['Contribution'].sum()\n",
    "# print(\"Total Contribution:\", total_contribution)\n",
    "\n",
    "# if total_contribution == 0:\n",
    "#     raise ValueError(\"Total contribution is zero. Cannot compute cumulative percentage contribution. Please check your data.\")\n",
    "# else:\n",
    "#     # Sort strategies by descending contribution\n",
    "#     strategy_contributions_df = strategy_contributions_df.sort_values(by='Contribution', ascending=False)\n",
    "\n",
    "#     # Calculate cumulative contribution\n",
    "#     strategy_contributions_df['CumulativeContribution'] = strategy_contributions_df['Contribution'].cumsum()\n",
    "#     strategy_contributions_df['CumulativeContributionPct'] = strategy_contributions_df['CumulativeContribution'] / total_contribution\n",
    "\n",
    "#     # Display the contributions DataFrame\n",
    "#     print(\"\\nStrategy Contributions DataFrame:\")\n",
    "#     print(strategy_contributions_df)\n",
    "\n",
    "#     # Select strategies that cumulatively contribute up to 80%\n",
    "#     selected_strategies = strategy_contributions_df[strategy_contributions_df['CumulativeContributionPct'] <= 0.8]['Strategy']\n",
    "\n",
    "#     # If no strategies are selected, adjust the threshold or selection method\n",
    "#     if selected_strategies.empty:\n",
    "#         # Option: Select the top N strategies\n",
    "#         N = 10  # For example, select top 10 strategies\n",
    "#         selected_strategies = strategy_contributions_df['Strategy'].head(N)\n",
    "#         print(f\"\\nNo strategies met the 80% cumulative contribution threshold. Selecting top {N} strategies instead.\")\n",
    "\n",
    "#     # **Subset original data for selected strategies**\n",
    "#     returns_selected = returns[selected_strategies]\n",
    "#     mean_returns_selected = mean_returns[selected_strategies]\n",
    "#     cov_matrix_selected = cov_matrix.loc[selected_strategies, selected_strategies]\n",
    "\n",
    "#     # Portfolio optimization parameters\n",
    "#     num_assets = len(selected_strategies)\n",
    "#     initial_weights = [1 / num_assets] * num_assets\n",
    "#     bounds = tuple((0, 0.1) for _ in range(num_assets))\n",
    "#     risk_free_rate = 0.01\n",
    "\n",
    "#     # Constraints for weights summing to 1\n",
    "#     constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "\n",
    "#     # Function to calculate portfolio performance\n",
    "#     def portfolio_performance(weights, mean_returns, cov_matrix):\n",
    "#         port_return = np.dot(weights, mean_returns)\n",
    "#         port_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "#         return port_return, port_std\n",
    "\n",
    "#     # Objective function to minimize volatility\n",
    "#     def minimize_volatility(weights):\n",
    "#         return portfolio_performance(weights, mean_returns_selected, cov_matrix_selected)[1]\n",
    "\n",
    "#     # Perform optimization\n",
    "#     min_vol_allocation = minimize(minimize_volatility, initial_weights,\n",
    "#                                   method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "#     # Check optimization success\n",
    "#     if not min_vol_allocation.success:\n",
    "#         print(\"Optimization failed:\", min_vol_allocation.message)\n",
    "#     else:\n",
    "#         # Extract optimal weights\n",
    "#         optimal_weights = min_vol_allocation.x\n",
    "\n",
    "#         # Calculate portfolio performance\n",
    "#         opt_return, opt_volatility = portfolio_performance(optimal_weights, mean_returns_selected, cov_matrix_selected)\n",
    "\n",
    "#         # Calculate Sharpe Ratio\n",
    "#         sharpe_ratio = (opt_return - risk_free_rate) / opt_volatility\n",
    "\n",
    "#         # Display results\n",
    "#         print(f\"\\nAllocation optimale avec PCA et stratégies priorisées :\")\n",
    "#         for i, weight in enumerate(optimal_weights):\n",
    "#             if abs(weight) > 0:  # Display only non-zero positions\n",
    "#                 print(f\"  {selected_strategies.iloc[i]}: {weight:.2%}\")\n",
    "#         print(f\"Rendement attendu: {opt_return:.2%}\")\n",
    "#         print(f\"Volatilité: {opt_volatility:.2%}\")\n",
    "#         print(f\"Ratio de Sharpe: {sharpe_ratio:.2f}\")\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "#         # Convert allocations to DataFrame\n",
    "#         allocations_df_pca = pd.DataFrame([optimal_weights], columns=returns_selected.columns)\n",
    "\n",
    "#         # Save to CSV\n",
    "#         allocations_df_pca.to_csv('optimal_allocations_pca.csv', index=False)\n",
    "\n",
    "#         # Display allocations DataFrame\n",
    "#         print(\"\\nDataFrame des allocations optimales basées sur PCA :\")\n",
    "#         print(allocations_df_pca)\n",
    "\n",
    "#         # Optional: Visualization\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.barh(returns_selected.columns, optimal_weights, color='skyblue')\n",
    "#         plt.xlabel('Poids des actifs')\n",
    "#         plt.title('Allocation optimale basée sur PCA et stratégies priorisées')\n",
    "#         plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
